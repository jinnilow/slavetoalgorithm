# Week 8
## Trial & Error

Following the pseudocode I made, I wanted to explore the different ways I could go about the project. I found a few different resources to help with facial/ emotion tracking. I have found this[ GitHub which explained more about using Face API to track facial expressions](https://github.com/justadudewhohacks/face-api.js), as well as [this one that used the API in ml5 instead of TensorFlow.js.](https://github.com/ml5js/ml5-library/pull/482) 

[This project also shows how he connects visuals according to the most recent emotion tracked.](https://github.com/pseudospencer/emojiCV ) I think this would be really helpful to learn as I figuring how I could connect the visuals to the tracked expressions.

I then stumbled across [The Coding Trainâ€™s learning playlist on machine learning,](https://www.youtube.com/playlist?list=PLRqwX-V7Uu6YPSwT06y_AEYTqIwbeam3y ) and this helped me further understand how machine learning works. I have been trying to explore how I could also use machine learning to train my expressions and to connect shapes to the range of expressions instead.

To start understanding machine learning, I was following the image classifying through the webcam tutorial posted by The Coding Train. However I couldn't get the image uploader to work as well as the text to display on the webcam screen instead of just showing it in the backend. 
<br/><br/> 
<img src="https://i.ibb.co/NYb0ggP/Screenshot-2020-09-18-at-1-08-36-PM-01.png" alt="Screenshot-2020-09-18-at-1-08-36-PM-01" border="0" width="500"/>
<br/><br/>


## In-Class Feedback
